{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SBNet : Sparse Block Network([arxiv](https://arxiv.org/abs/1801.02108))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNs are widely used for analyzing visual imagery and data from LiDAR sensors. In autonomous driving, CNNs allow self-driving vehicles to see other cars and pedestrians, determine their exact locations, and solve many other difficult problems that could not previously be tackled with conventional algorithms. To ensure that our autonomous systems are reliable, such applications of CNNs must run at extremely fast speeds on GPUs. Developing efficient ways to improve response time and accuracy while reducing device costs and power consumption with CNNs is an ongoing research priority.   \n",
    "\n",
    "The development of model architectures and algorithms in the field of deep learning is largely constrained by the availability of efficient GPU implementations of elementary operations. One issue has been the lack of an efficient GPU implementation for sparse linear operations.\n",
    "\n",
    "Conventional deep CNNs apply convolution operators uniformly for all spatial locations across hundreds of layers, requiring trillions of operations per second. The knowledge that many of these operations are wasted on over analyzing irrelevant information. In a typical scene, only a small percentage of observed data is important, this is sparsity. The way we see, the visual cortex exploits sparsity by focusing foveal vision based on movement detected in the peripheral vision and reducing receptor density and color information in the peripheral portions of the retina.\n",
    "\n",
    "SBnet forces the CNN's to focus (attention) only on the object in the image, using a mask. Since, the rest of the image is blocked from its view (not given as input), CNN's don't convolve over these sparse regions. Thereby, reducing the number of compute operations.\n",
    "\n",
    "\n",
    "![attention_blocks](https://github.com/Sharwon/EIP/raw/master/final_project/images/sbnet.gif \"http://www.cs.toronto.edu/~byang/\")\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - SBnet proposes to reduce computation in the high resolution main network using low-cost computation mask. Here, low-cost means, generating masks using very less resources.\n",
    " \n",
    " - It leverages the spatial sparsity structure of the mask.\n",
    " \n",
    " - The two main contributions of this paper are\n",
    "         1. Tiling-based sparse convolution algorithm.\n",
    "         2. Implementation of their sparse block algorithm using custom CUDA kernels.\n",
    " \n",
    " - The spatial sparsity can be represented as **binary** computation mask where ones indicate active locations that need more computation and zeros inactive.\n",
    " \n",
    " - These computation masks can be considered as attention mechanism where the attention weights are binary. These are used to guide the convolution filters.\n",
    " - SBnet computes convolution on a **blockwise** decomposition of the mask.\n",
    " - It gathers block-wise slices from tensors, and maintains the tensor shape. Within each active block, it performs a regular convolution, and uses **Winograd convolutions** for further speedup.\n",
    " - Block sparsity is defined in terms of a mask that can be known upfront like a priori sparsity structure, or that can be computed easily. (as mentioned before)\n",
    " - The same **sparsity mask** is reused for every layer, but uses reduced **spatial block** sizes at different spatial scales. It helps in maintaining speed without loss in accuracy.\n",
    " - Two major building blocks in sparse block-wise convolution-\n",
    "   ![image1](https://github.com/Sharwon/EIP/raw/master/final_project/images/tiling-algo.png \"Credits to paper\")\n",
    "      1. **Reduce mask to indices** : It converts the binary mask [H, W, C] (input) to a list of indices[B,3], where each indices references the location of the active blocks in the input tensor. The bock size is uniform, so that the gathered blocks can be batched together and passed into a convolution operation. After getting the appropriate block and overlap sizes, we perform a pooling(max/avg) operation followed by a threshold to downsample the input mask. We extract the patches from the non-zero locations.\n",
    "      \n",
    "   ![image2](https://github.com/Sharwon/EIP/raw/master/final_project/images/block-sparse.png \"Credits to paper\")\n",
    "      2. **Sparse gather/scatter** : Gathering extracts a block[B, h, w, C] from the input tensor [N, H, W, C], using the generated indexes[B,3]. Unlike, tf.gather_nd(other gather kernel), this expands spatially to their neighborhood windows. The input overlap is essential to producing the output that seamlessly stitches the results of adjacent block convolution in a way that is locally equivalent to a dense convolution on a larger block and fused indexing capability is fundamental to practical speedup. The Scatter operation is inverse to the gather operation, reusing the same input mask and block index list. Input tensor [B, h`, w`, C] is the result after a series of convolution from the output of gather kernel, then a valid convolution is applied on the input tensor. The results of this convolution is copied back on the top of the dense activation tensor. \n",
    "     \n",
    "  - A single residual layer has 3 convolutions, BatchNorm and Relu layers. All 9 layers can share a single gathering and scattering operation without block overlap, because it retains the same receptive field.\n",
    "    \n",
    "   ![image3](https://github.com/Sharwon/EIP/raw/master/final_project/images/residualsparseblock.png \"Credits to paper\")\n",
    "  - We need to train Resnet-Sbnet end to end as BatchNorm statics differ for sparse connections. The gradient for scatter operation is the gather operation with the same precomputed block indices executed on the next layers backpropagated gradient tensor and vice versa. Also, keep in mind the edges of overlapping tiles.\n",
    "  - **Custom Cuda Kernels**, were necessary to achieve speed-ups in practice. To minimize the intermediate outputs between kernels, they **fused downsample and indexing kernels** into one. Also **fused transpose + gather/scatter kernels**, as cuDNN runs faster with NCHW format. The gather/scatter kernel fuses the transpose from NHWC to NCHW tensor data inside the CUDA kernel. This is instrumental in achieving practical speed (eliminating transpose round-up trip). They were adamant in using NHWC format as it allows for memory-coalesced-contiguous access of spatially perforated blocks. **fused scatter-add kernel for residual blocks** helps in achieving faster inference time, by eliminating the extra memory allocation(reused output).\n",
    "    ![image5](https://github.com/Sharwon/EIP/raw/master/final_project/images/tfopscustomcuda.png)\n",
    "  - They implemented custom TensorFlow Ops to interface with the Cuda kernels.\n",
    "  - It's benchmarked with sparse manifold convolution. Both layerwise and network benchmarks are compared.\n",
    "  - The experiments and results are discussed a later section of this notebook.\n",
    "  \n",
    "  ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "I've downloaded a video from youtube, which records a road lane.  \n",
    "Let's generate a dataset which has two classes (vehicles, no_vehicles) and their respective mask. It should look something like this.\n",
    "\n",
    "![Image2](https://camo.githubusercontent.com/2328970cc768f21d5c7591fbccea6dff42a4df8d/687474703a2f2f692e67697068792e636f6d2f35413934415a61685349564f772e676966)\n",
    "\n",
    "There are many techniques to realize this problem statement. Basically, we have to make a mask for moving objects.  \n",
    "The simplest way to achieve this is by using foreground detection using background subtraction technique. Where in we take the first frame as the reference frame, and detect changes, by subtracting it from the next frame. For more details checkout the references at the end of this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(video_file):\n",
    "    '''\n",
    "    Input : location of the video input (video_file)\n",
    "    Output : Creates folders(sorted images) inside your directory depending upon the classes and masks\n",
    "    '''\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "    count = 0\n",
    "    #  VIDEO PROPERTIES\n",
    "    print(\"Frame Width : \")\n",
    "    print(cap.get(3))  # Frame Width\n",
    "    print(\"Frame Height :\")\n",
    "    print(cap.get(4))  # Frame Height\n",
    "    fps = (cap.get(cv2.CAP_PROP_FPS))\n",
    "    print(\"FPS :\", fps)\n",
    "    # create a mask from the extacted frame.\n",
    "    fullmask = cv2.createBackgroundSubtractorMOG2()\n",
    "    while (cap.isOpened):\n",
    "        ret, frame = cap.read()\n",
    "        fgmask = fullmask.apply(frame)\n",
    "        if fgmask is None:\n",
    "            break\n",
    "        (im2, contours, hierarchy) = cv2.findContours(fgmask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        for c in contours:\n",
    "            if cv2.contourArea(c) < 600: # removes smaller moving objects.\n",
    "                continue\n",
    "\n",
    "            filename_frame = \"/Users/ubuntu/files/frames/frame_%d.jpg\" % count\n",
    "            # resize image\n",
    "            resized_frame = cv2.resize(frame, (128,128), interpolation=cv2.INTER_AREA)\n",
    "            cv2.imwrite(filename, resized_frame)\n",
    "\n",
    "            filename_mask = \"/Users/ubuntu/files/fgmask/fgmask_%d.jpg\" % count\n",
    "            # resize image\n",
    "            resized_fgmask = cv2.resize(fgmask, (128,128), interpolation=cv2.INTER_AREA)\n",
    "            # writing the image to a file.\n",
    "            cv2.imwrite(filename, resized_fgmask)\n",
    "            count = count + 1\n",
    "\n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My initial result....  \n",
    "![gif](https://github.com/Sharwon/EIP/raw/master/final_project/images/background.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now from the generated images and mask. I sorted images into four folders.  \n",
    "vehicles, vehicles_mask, no_vehicles, no_vehicles_mask are the respective folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the images as tensor files.\n",
    "def convert_i2t(ROOT_DIR, STORE_DIR):\n",
    "    '''\n",
    "    ROOT_DIR : The directory of the image files.\n",
    "    STORE_DIR : The directory of the saved image files.\n",
    "    '''\n",
    "    def save(fname, save_loc):\n",
    "        '''\n",
    "        fname : file name of the image\n",
    "        save_loc : location where the pickle files are to be stores.\n",
    "        '''\n",
    "        sfile = bz2.BZ2File(fname, 'w')\n",
    "        pickle.dump(save_loc, sfile)\n",
    "        sfile.close()\n",
    "\n",
    "\n",
    "    def process(DIR, STORE_DIR = \"numpy_array/\", color = 1):\n",
    "        '''\n",
    "        DIR : Directory which contains the images\n",
    "        color : 1 reads in RGB, 0 reads in greyscale \n",
    "        '''\n",
    "        image_list = os.listdir(os.path.join(ROOT_DIR, DIR))\n",
    "        image_list.sort()\n",
    "        for i in range(len(image_list)) :\n",
    "            if i == 0 :\n",
    "                img = cv2.imread(os.path.join(ROOT_DIR, DIR, image_list[i]), color)\n",
    "                img_shape = img.shape \n",
    "                #torch expects tensors in shape N,C,H,W unlike keras,(N,H,W,C)\n",
    "                data = np.empty((0, img_shape[2], img_shape[0], img_shape[1]))\n",
    "                img = np.swapaxes(img, 0, 2)\n",
    "                img = np.swapaxes(img, 1, 2)\n",
    "                data = np.concatenate((data, img[np.newaxis, :, :, :]), axis = 0)\n",
    "            else :\n",
    "                img =  cv2.imread(os.path.join(ROOT_DIR, DIR, image_list[i]), color)\n",
    "                img = np.swapaxes(img, 0, 2)\n",
    "                img = np.swapaxes(img, 1, 2)\n",
    "                data = np.concatenate((data, img[np.newaxis, :, :, :]), axis = 0)\n",
    "        save(STORE_DIR + DIR + \".bz2\", data)\t\n",
    "        return data\n",
    "\n",
    "\n",
    "    data_list = os.listdir(ROOT_DIR)\n",
    "    print(data_list)\n",
    "\n",
    "    for i in data_list:\n",
    "        process(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T10:46:05.323811Z",
     "start_time": "2018-06-22T10:45:59.799522Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "DVCPf60bgMdZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no_vehicles_frames', 'vehicles_frames', 'no_vehicles_mask', 'vehicles_fgmask']\n"
     ]
    }
   ],
   "source": [
    "# the output should be like this, below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Code Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've created a dataset of two classes. 20 images and 20 masks for each class.  \n",
    "I have done experiments with other datasets as well, links are provided in the log's section.  \n",
    "Where you can shift+enter the whole notebook in google colab.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-24T21:53:06.537427Z",
     "start_time": "2018-06-24T21:53:06.191343Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2944,
     "status": "ok",
     "timestamp": 1529480001398,
     "user": {
      "displayName": "Ddev Ddev",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "114475786811527419051"
     },
     "user_tz": -330
    },
    "id": "RSIklmozHIqy",
    "outputId": "86878b1d-dd07-4a9b-ee98-9bf9ad790352"
   },
   "outputs": [],
   "source": [
    "# data loading and pre-processing\n",
    "import pickle\n",
    "import bz2\n",
    "import os\n",
    "#image processing tools\n",
    "import numpy as np \n",
    "import cv2\n",
    "from IPython.display import Image\n",
    "#deep learning framework\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np \n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "#ploting images\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "#plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-24T21:17:12.260684Z",
     "start_time": "2018-06-24T21:17:12.230303Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_SjFSkub0Iyc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommended to run these functions seperately, as a python script.\n",
    "\n",
    "#creating dataset as mentioned before.\n",
    "create_dataset(\"location of the video file\")\n",
    "\n",
    "'''\n",
    "Sorted images into four folders.\n",
    "vehicles, vehicles_mask, no_vehicles, no_vehicles_mask are the respective folders.\n",
    "'''\n",
    "\n",
    "# convert these images into b2z file (for loading them as numpy arrays)\n",
    "convert_i2t(ROOT_DIR, STORE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the saved bz2 files into a torch tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download the dataset form [here](https://github.com/Sharwon/EIP/blob/master/final_project/images_sbnet_smaple.zip) and run from the next cell, onwards. Don't forget to unzip and 'cd' into the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-24T21:17:27.852972Z",
     "start_time": "2018-06-24T21:17:22.176660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 3, 128, 128])\n",
      "torch.Size([20, 3, 128, 128])\n",
      "torch.Size([20, 3, 128, 128])\n",
      "torch.Size([20, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "# Loading the saved bz2 files\n",
    "def loadBz2(name): \n",
    "\tload_file = bz2.BZ2File(name, 'rb')\n",
    "\tdata = pickle.load(load_file)\n",
    "\tload_file.close()\n",
    "\treturn data\n",
    "\n",
    "\n",
    "no_vehicles = loadBz2(\"numpy_array/no_vehicles_frames.bz2\")\n",
    "no_vehicles_mask = loadBz2(\"numpy_array/no_vehicles_fgmask.bz2\")\n",
    "vehicles = loadBz2(\"numpy_array/vehicles_frames.bz2\")\n",
    "vehicles_mask = loadBz2(\"numpy_array/vehicles_fgmask.bz2\")\n",
    "\n",
    "# Converting them to torch tensor\n",
    "no_vehicles = torch.Tensor(no_vehicles).to(device)\n",
    "no_vehicles_mask = torch.Tensor(no_vehicles_mask).to(device)\n",
    "vehicles = torch.Tensor(vehicles).to(device)\n",
    "vehicles_mask = torch.Tensor(vehicles_mask).to(device)\n",
    "print(no_vehicles.size())\n",
    "print(no_vehicles_mask.size())\n",
    "print(vehicles.size())\n",
    "print(vehicles_mask.size())\n",
    "\n",
    "#The shape should be N,C,H,W (pytorch format)\n",
    "#The model and the data must be on the same device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-24T21:19:51.363750Z",
     "start_time": "2018-06-24T21:19:51.351192Z"
    }
   },
   "outputs": [],
   "source": [
    "# Making the training data into a pytorch readable format.\n",
    "\n",
    "X_train = torch.cat((vehicles, no_vehicles), 0).to(device)\n",
    "Y_train = torch.cat((torch.zeros(20,1), torch.ones(20,1)), 0).to(device)\n",
    "#normalizing the dataset\n",
    "X_train = X_train/255\n",
    "Mask = torch.cat((vehicles_mask, no_vehicles_mask), 0).to(device)\n",
    "Mask_t = (Mask > (10/255)).float()\n",
    "Mask_t = Mask_t[:,0,:,:] # the mask format [B,H,W]\n",
    "Mask_t.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-24T21:12:41.242Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 3, 128, 128])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape #[N,C,H,W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-24T16:47:36.080437Z",
     "start_time": "2018-06-24T16:47:36.072361Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 128, 128])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mask_t.shape #[N,H,W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 128, 128])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_t=Mask_t.clone()\n",
    "mask_t[Mask_t==0]=1\n",
    "mask_t[Mask_t==1]=0\n",
    "mask_t.requires_grad = False\n",
    "mask_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-24T21:26:19.571140Z",
     "start_time": "2018-06-24T21:26:18.818029Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# image\n",
    "plt.imshow(X_train[7,0, :, :])\n",
    "plt.set_cmap(cmap = cm.gray)\n",
    "plt.title(\"Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-24T21:30:28.782527Z",
     "start_time": "2018-06-24T21:30:28.545383Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# image's mask\n",
    "plt.imshow(mask_t[7, :, :])\n",
    "plt.set_cmap(cmap = cm.gray)\n",
    "plt.title(\"Mask\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-24T16:46:06.260595Z",
     "start_time": "2018-06-24T16:46:06.253505Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Om7iADHd0CDq"
   },
   "outputs": [],
   "source": [
    "# learning parameters\n",
    "num_epochs = 5\n",
    "num_classes = 2\n",
    "batch_size = 4\n",
    "learning_rate = 0.01\n",
    "img_channel, img_height, img_width = X_train.shape[1], X_train.shape[2], X_train.shape[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom SBnet Module Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-24T21:34:36.697655Z",
     "start_time": "2018-06-24T21:34:36.667988Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5NlUO5260zeN"
   },
   "outputs": [],
   "source": [
    "def pad_input(input, ksize, kstride):\n",
    "    '''\n",
    "    Pads the input or mask according to the required kernel to perform sparse convolution\n",
    "\n",
    "    Inputs:\n",
    "    :param input:  torch tensor  #[N,H,W] binary mask or [N,C,H,W] input, where N is batch diemension, W, H are width and height of mask and C is channels\n",
    "    :param kszie:  [list, tuple]  #[h,w] Size of kernel to perform pooling\n",
    "    :param kstride:  [list, tuple]  #[h_stride,w_stride] Stride of Kernel\n",
    "\n",
    "    Output: Zero padded torch tensor\n",
    "    '''\n",
    "    assert torch.is_tensor(input) == True, 'Expect input to be a pytorch tensor'\n",
    "    isize = list(input.size())\n",
    "    assert len(input.size()) == 3 or len(input.size()) == 4, 'Expect input rank = 3(mask) or 4(input)'\n",
    "    assert type(ksize) in [list, tuple], 'Expect `ksize` to be list or tuple'\n",
    "    assert type(kstride) in [list, tuple], 'Expect `kstride` to be list or tuple'\n",
    "    assert len(kstride) == 2 and len(ksize) == 2, 'Expect length of kstride and ksize to be 2'\n",
    "\n",
    "    #padding along width!\n",
    "    pad_w = kstride[-1] - ((isize[-1]-ksize[-1])%kstride[-1])\n",
    "    pad_w1 = pad_w2 = pad_w//2\n",
    "    if pad_w%2 == 1:\n",
    "        pad_w2 += 1\n",
    "\n",
    "    #padding along height\n",
    "    pad_h = kstride[-2] - ((isize[-2]-ksize[-2])%kstride[-2])\n",
    "    pad_h1 = pad_h2 = pad_h//2\n",
    "    if pad_h%2 == 1:\n",
    "        pad_h2 += 1\n",
    "\n",
    "    pad = (pad_w1, pad_w2, pad_h1, pad_h2)\n",
    "    return F.pad(input, pad, \"constant\", 0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-24T21:36:40.018072Z",
     "start_time": "2018-06-24T21:28:09.856Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "h8vSNw2g0CGD"
   },
   "outputs": [],
   "source": [
    "def reduce_mask_pool2d(mask, ksize, kstride, thresh = 0.2, avg= True):\n",
    "    '''\n",
    "    Reduce mask operation:Takes a binary mask as input and after performing \n",
    "    avg pooling or max pooling selects active blocksand return indices of \n",
    "    the active blocks\n",
    "\n",
    "    Inputs:\n",
    "    :param mask:  torch tensor  #[N,H,W] binary mask, where N is batch diemension, W, H are width and height of mask\n",
    "    :param kszie:  [list, tuple]  #[h,w] Size of kernel to perform pooling\n",
    "    :param kstride:  [list, tuple]  #[h_stride,w_stride] Stride of Kernel\n",
    "    :param thresh:  int   #applicable for avg pooling\n",
    "    :param avg:  bool   #Avg pooling or max pooling \n",
    "\n",
    "    Require_grad = Fasle\n",
    "\n",
    "    Output:\n",
    "        indicies of size [B, 3] where B is the number of active blocks \n",
    "        and 3 corresponds to [N, y, x] where N is batch size, and (y,x) is the \n",
    "        co-ordinates of the \"centre\" of the block.\n",
    "        indicies is a torch tensor\n",
    "    Note:\n",
    "        padding is done automatically\n",
    "    '''\n",
    "\n",
    "    assert torch.is_tensor(mask) == True, 'Expect mask to be a pytorch tensor'\n",
    "    isize = list(mask.size())\n",
    "    assert len(mask.size()) == 3 , 'Expect input rank = 3'\n",
    "    assert type(ksize) in [list, tuple], 'Expect `ksize` to be list or tuple'\n",
    "    assert type(kstride) in [list, tuple], 'Expect `kstride` to be list or tuple'\n",
    "    assert len(kstride) == 2 and len(ksize) == 2, 'Expect length of kstride and ksize to be 2'\n",
    "    assert type(thresh) in [int, float], 'Expect `thresh` to be int or float'\n",
    "\n",
    "    mask = mask.unsqueeze(1)\n",
    "\n",
    "    if avg:\n",
    "        temp = F.avg_pool2d(input = mask, kernel_size = ksize, stride = kstride, padding = 0).to(device).squeeze()\n",
    "        indicesm = torch.where(temp > thresh, torch.ones_like(temp).to(device), torch.zeros_like(temp).to(device)).int()\n",
    "        indices = (indicesm != 0).nonzero().to(device)\n",
    "        return indices\n",
    "    else:\n",
    "        temp = F.max_pool2d(input = mask, kernel_size = ksize, stride = kstride, padding = 0).to(device).squeeze()\n",
    "        indicesm = torch.where(temp > thresh, torch.ones_like(temp).to(device), torch.zeros_like(temp).to(device)).int()\n",
    "        indices = (indicesm != 0).nonzero().to(device)\n",
    "        return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-24T21:36:40.033191Z",
     "start_time": "2018-06-24T21:28:12.986Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "0-NkaloR01jE"
   },
   "outputs": [],
   "source": [
    "def mask_pool2d(mask):\n",
    "    '''\n",
    "    mask downsample operation:Takes a binary mask as input and performs max\n",
    "    pooling to reduce its size \n",
    "\n",
    "    Inputs:\n",
    "    :param mask: torch tensor size[N,H,W] binary mask, where N is batch diemension, W, H are width and height of mask\n",
    "\n",
    "    Outputs: A binary torch tensor of half the input mask size\n",
    "    '''\n",
    "    assert torch.is_tensor(mask) == True, 'Expect mask to be a pytorch tensor'\n",
    "    isize = list(mask.size())\n",
    "    assert len(mask.size()) == 3 , 'Expect input rank = 3'\n",
    "\n",
    "    mask = mask.unsqueeze(1)\n",
    "    temp = F.max_pool2d(input = mask, kernel_size = [2,2], stride = [2,2], padding = 0).to(device).squeeze().float()\n",
    "    temp.require_grad = False\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-24T21:36:40.050174Z",
     "start_time": "2018-06-24T21:28:16.243Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "1CefJdko04HE"
   },
   "outputs": [],
   "source": [
    "#Functions gather and scatter in  nn.Module class to allow easier flow of gradients\n",
    "\n",
    "class gather2dc(nn.Module):\n",
    "    def __init__(self, ksize, kstride):\n",
    "        super(gather2dc, self).__init__()\n",
    "        '''\n",
    "        gather operation: Gathers the tile blocks (input) from the given indicies.\n",
    "\n",
    "        Inputs:\n",
    "        :param indices: indicies of size [B, 3] where B is the number of active blocks.\n",
    "        :param kstride:  [list, tuple]  #[h_stride,w_stride] Stride of Kernel\n",
    "        :param kszie:  [list, tuple]  #[h,w] Size of kernel to perform pooling        \n",
    "\n",
    "        Outputs: Gathered blocks\n",
    "        '''\n",
    "        assert type(kstride) in [list, tuple], 'Expect `kstride` to be list or tuple'\n",
    "        assert len(kstride) == 2 and len(ksize) == 2, 'Expect length of kstride and ksize to be 2'\n",
    "        self.ksize = ksize\n",
    "        self.kstride = kstride\n",
    "\n",
    "    def forward(self, input, indices):\n",
    "        gathered = input[indices[0][0]:indices[0][0]+1, :, indices[0][1]*self.kstride[0]:indices[0][1]*self.kstride[0]+self.ksize[0], indices[0][2]*self.kstride[1]: indices[0][2]*self.kstride[1]+self.ksize[1]]\n",
    "        for B, h0, w0 in indices[1:]:\n",
    "            gathered = torch.cat((gathered, input[B:B+1, :, h0*self.kstride[0]:h0*self.kstride[0]+self.ksize[0], w0*self.kstride[1]: w0*self.kstride[1]+self.ksize[1]]), 0)\n",
    "        return gathered\n",
    "\n",
    "\n",
    "class scatter2dc(nn.Module):\n",
    "    def __init__(self, kstride):\n",
    "        super(scatter2dc, self).__init__()\n",
    "        '''\n",
    "        scatter operation: Scatters the results of the operation back onto the input blocks given by gathered.\n",
    "\n",
    "        Inputs:\n",
    "        :param gathered: varies according to each batch of the input.\n",
    "        :param kstride:  [list, tuple]  #[h_stride,w_stride] Stride of Kernel    \n",
    "\n",
    "        Outputs: Updated Input\n",
    "        '''\n",
    "        assert type(kstride) in [list, tuple], 'Expect `kstride` to be list or tuple'\n",
    "        self.kstride = kstride\n",
    "\n",
    "    def forward(self, input, gathered, indices):\n",
    "        gsize = list(gathered.size())\n",
    "        count_index = 0\n",
    "        for B, h0, w0 in indices:\n",
    "                input[B, :, h0*self.kstride[0]:h0*self.kstride[0]+gsize[2], w0*self.kstride[1]: w0*self.kstride[1]+gsize[3]] = gathered[count_index]\n",
    "                count_index +=1\n",
    "        return input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-24T17:14:42.950424Z",
     "start_time": "2018-06-24T17:14:42.927824Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JA1bA6Nw07Cz"
   },
   "outputs": [],
   "source": [
    "class sparse_block(nn.Module):\n",
    "    def __init__(self, inp_ch, out_ch, ksize, kstride, block_layers = None, thresh = 0.2):\n",
    "        super(sparse_block, self).__init__()\n",
    "\n",
    "        assert type(block_layers) in [type(None), torch.nn.modules.container.Sequential], 'Expect block_layers as None or torch.nn.Sequential() object' \n",
    "        assert type(ksize) in [list, tuple], 'Expect `ksize` to be list or tuple'\n",
    "        assert type(kstride) in [list, tuple], 'Expect `kstride` to be list or tuple'\n",
    "        assert len(kstride) == 2 and len(ksize) == 2, 'Expect length of kstride and ksize to be 2'\n",
    "        assert type(inp_ch) in [int, float], 'inp_ch should be int or float'\n",
    "        assert type(out_ch) in [int, float], 'out_ch should be int or float'\n",
    "        self.ksize = ksize\n",
    "        self.kstride = kstride\n",
    "        self.thresh = thresh\n",
    "        self.g = gather2dc(ksize, kstride)\n",
    "        self.c = scatter2dc(kstride)\n",
    "        self.channel_control =  nn.Sequential(\n",
    "            nn.Conv2d(inp_ch, out_ch, 1, padding = 0),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(out_ch)).to(device)\n",
    "\n",
    "        if block_layers == None:\n",
    "            self.operation = nn.Sequential(\n",
    "                nn.Conv2d(out_ch, 2*out_ch, 1, padding = 0),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(2*out_ch),\n",
    "                nn.Conv2d(2*out_ch, 2*out_ch, 3, padding = 1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(2*out_ch), \n",
    "                nn.Conv2d(2*out_ch, out_ch, 1, padding = 0),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(out_ch)\n",
    "                ).to(device)\n",
    "        else:\n",
    "            self.operation = block_layers.to(device)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = self.channel_control(x)\n",
    "        mask = pad_input(mask, self.ksize, self.kstride)\n",
    "        mask.require_grad = False\n",
    "        x = pad_input(x, self.ksize, self.kstride)\n",
    "        x.require_grad = True\n",
    "\n",
    "        indices = reduce_mask_pool2d(mask, self.ksize, self.kstride, self.thresh, avg= True)\n",
    "        gathered = self.g(x, indices)\n",
    "        gathered = self.operation(gathered)\n",
    "        x = self.c(x, gathered, indices)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-24T17:16:14.666341Z",
     "start_time": "2018-06-24T17:16:14.647801Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "s7FzWm-S0CIM"
   },
   "outputs": [],
   "source": [
    "class net(nn.Module):\n",
    "    def __init__(self, inp_ch, num_classes):\n",
    "        super(net, self).__init__()\n",
    "        self.sparse1 = sparse_block(inp_ch, 16, [5,5], [4,4], thresh = 0.20)\n",
    "        self.mp1 = nn.MaxPool2d(2)\n",
    "        self.sparse2 = sparse_block(16, 32, [5,5], [4,4], thresh = 0.20)\n",
    "        self.mp2 = nn.MaxPool2d(2)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2*128*128, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, num_classes-1),\n",
    "            nn.Softmax(dim=1)\n",
    "            #nn.Sigmoid()\n",
    "            )\n",
    "\n",
    "    def forward(self, x, mask1):\n",
    "        x = self.sparse1(x, mask1)\n",
    "        x = self.mp1(x)\n",
    "        mask2 = mask_pool2d(mask1)\n",
    "        x = self.sparse2(x, mask2)\n",
    "        x = self.mp2(x)\n",
    "        #print(x.size()) \n",
    "        x = x.view(batch_size, -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-24T17:33:59.247670Z",
     "start_time": "2018-06-24T17:33:59.238562Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of net(\n",
       "  (sparse1): sparse_block(\n",
       "    (g): gather2dc()\n",
       "    (c): scatter2dc()\n",
       "    (channel_control): Sequential(\n",
       "      (0): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (operation): Sequential(\n",
       "      (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): ReLU()\n",
       "      (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (7): ReLU()\n",
       "      (8): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (mp1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (sparse2): sparse_block(\n",
       "    (g): gather2dc()\n",
       "    (c): scatter2dc()\n",
       "    (channel_control): Sequential(\n",
       "      (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (operation): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): ReLU()\n",
       "      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (7): ReLU()\n",
       "      (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (mp2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=32768, out_features=100, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=100, out_features=1, bias=True)\n",
       "    (3): Softmax()\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating model template\n",
    "model = net(img_channel, num_classes).to(device)\n",
    "\n",
    "model.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-24T17:16:56.851247Z",
     "start_time": "2018-06-24T17:16:56.752104Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "hidden": true,
    "id": "Hxk9s2eJ0CKt"
   },
   "outputs": [],
   "source": [
    "# Using Binary Cross entropy loss\n",
    "criterion = nn.BCELoss()\n",
    "# Adam optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-24T17:26:47.339853Z",
     "start_time": "2018-06-24T17:19:01.567034Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1788,
     "status": "ok",
     "timestamp": 1529468803557,
     "user": {
      "displayName": "Ashwin Kulkarni",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "106069713485154044351"
     },
     "user_tz": -330
    },
    "id": "coQPKW_P0CPA",
    "outputId": "4fd888de-fbe8-42b9-fca2-cc02d2c3fa91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch =  1\n",
      "Step [9/10], Loss: 15.3506 \n",
      "Epoch =  2\n",
      "Step [9/10], Loss: 15.3506 \n",
      "Epoch =  3\n",
      "Step [9/10], Loss: 15.3506 \n",
      "Epoch =  4\n",
      "Step [9/10], Loss: 15.3506 \n",
      "Epoch =  5\n",
      "Step [9/10], Loss: 15.3506 "
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    epoch_loss = 0\n",
    "    print(\"\\nEpoch = \", epoch)\n",
    "    z = 0 # Steps in a single loop\n",
    "    for i in range(len(X_train)//batch_size):\n",
    "        x = X_train[z:z+batch_size, :, :, :]\n",
    "        y = Y_train[z:z+batch_size]\n",
    "        mask = Mask_t[z:z+batch_size, :, :]\n",
    "        z += batch_size\n",
    "        \n",
    "        #Forward pass\n",
    "        output = model(x, mask)\n",
    "        loss = criterion(output, y)\n",
    "        \n",
    "        #Backward pass\n",
    "        optimizer.zero_grad() # clearning previous stored gradients.\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        #print(epoch_loss)\n",
    "        if z%10 == 0:\n",
    "            print('\\rStep [{}/{}], Loss: {:.4f}'.format(i, len(X_train)//batch_size, epoch_loss/i), end = ' ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "eCr9pk1jV_UX"
   },
   "source": [
    "### Model Compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T13:49:22.204488Z",
     "start_time": "2018-06-23T13:48:54.986373Z"
    }
   },
   "source": [
    "The above code is just to give an idea on how to implement sbnet.\n",
    "\n",
    "I have tried the same code on a different datasets. Classifying between a car and a pedestrian.\n",
    "Click this [link](https://github.com/Sharwon/EIP/blob/master/final_project/sbnet_Binary_Classifier.ipynb) to check it out.  \n",
    "Here, the accuracy as well as the time constraints are being shown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Experiments mentioned in the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The authors have benchmarked the result with the sub-manifold algorithm using the same resources.([KITTI dataset]())    \n",
    "1) Synthetic masks generated using the top-left sub-region of input images to measure the practical upper bound on speed-up.  \n",
    "2) Road map masks obtained from our offline map data in TOR4D.  \n",
    "3) Predicted masks obtained from the outputs of PSPNet(gives better masks than background subtraction).  \n",
    "\n",
    "Compared detection accuracy with two baselines:  \n",
    "1) Dense: a dense network trained on all detection groundtruth.  \n",
    "2) Dense w/ Road Mask: a dense network trained on detection groundtruth within the road mask, i.e. treating regions outside the road as the ignore region. \n",
    "\n",
    "![results](https://github.com/Sharwon/EIP/raw/master/final_project/images/result.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sbnet works better on applications like object detection and segmentation.\n",
    "- In this notebook, we tried it for classification. Also, try augmentation for both image and mask.\n",
    "- This is not limited to convolution neural networks, cause sparsity is present ubiquitously. So it can be tried on other networks as well. The fundamental problem would be to come up with a mask for architectures like Deep LSTM's (language models).\n",
    "- Personally, I would like to test this architecture on coco and kitti dataset. And, replicate the results mentioned in the paper.\n",
    "- I think this will be pretty useful in tasks where we have to localizing objects on a 3d plane (fast inference), especially in UAV applications. And, help us in running computation hungry deep learning models, locally on a embedded platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Future prospects, are to complete these logs.\n",
    "\n",
    "1. Compiling the sbnet module locally (My laptop: GForce 920m).[link](https://github.com/uber/sbnet/)  \n",
    " -  Sbnet didn't compile, needs moder nvidia architectures like volta.  \n",
    " -  Tensorflow ops interfacing.  \n",
    "2. Generating a dataset(opencv).[link](https://github.com/Sharwon/EIP/blob/master/final_project/opencv_dataset.py)\n",
    "3. Training resnet model with the generated dataset.[link](https://github.com/Sharwon/EIP/blob/master/final_project/resnet_binay_image_classifier.ipynb)\n",
    "4. Compiling SBnet in Google Colab.[link](https://github.com/Sharwon/EIP/blob/master/final_project/sbnet-new.zip)  \n",
    "5. Aws sbnet tensorflow compilation.[link]() (Check out sbnet-new)  \n",
    "6. **RESNET SBNET** tensorflow aws.[link](https://github.com/Sharwon/EIP/blob/master/final_project/resnet_sbnet_full.ipynb)  \n",
    "7. Google colab sbnet pytorch.[link](https://github.com/Sharwon/EIP/blob/master/final_project/sbnet_Binary_Classifier.ipynb)  \n",
    "\n",
    "This [document](https://github.com/Sharwon/EIP/blob/master/project.adoc) shows my work flow. Most of my work is recorded here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.[SBnet white paper](https://arxiv.org/abs/1801.02108)  \n",
    "2.[Sbnet gihub repo](https://github.com/uber/sbnet/)  \n",
    "3.[Sbnet blog](https://eng.uber.com/sbnet/)  \n",
    "4.[Submanifold white paper](https://arxiv.org/abs/1706.01307)  \n",
    "5.[Tensorflow-ops](https://www.tensorflow.org/extend/adding_an_op)  "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Copy_of_SBNET_MNIST_(1).ipynb",
   "provenance": [
    {
     "file_id": "1tUoOxmp-Eo3mXMAwlcRx5ujf39c7Ddbl",
     "timestamp": 1529298390179
    },
    {
     "file_id": "1uvz9lNwk7K87vZdvzOIfO4y7UMiSoLDO",
     "timestamp": 1529295931055
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
